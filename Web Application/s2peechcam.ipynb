{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darsh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(r\"C:\\Users\\Darsh\\Desktop\\Project\\mp\\FinalCode\\modelfinal.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    0: 'A', \n",
    "    1: 'B', \n",
    "    2: 'C', \n",
    "    3: 'D', \n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'G',\n",
    "    7: 'H',\n",
    "    8: 'I',\n",
    "    9: 'J',\n",
    "    10: 'K',\n",
    "    11: 'L',\n",
    "    12: 'M',\n",
    "    13: 'N',\n",
    "    14: 'O',\n",
    "    15: 'P',\n",
    "    16: 'Q',\n",
    "    17: 'R',\n",
    "    18: 'S',\n",
    "    19: 'T', \n",
    "    20: 'U', \n",
    "    21: 'V',\n",
    "    22: 'W',\n",
    "    23: 'X',\n",
    "    24: 'Y',\n",
    "    25: 'Z',\n",
    "    26: 'del',\n",
    "    27: 'nothing',\n",
    "    28: 'space'\n",
    "}\n",
    "\n",
    "color_dict=(0,255,0)\n",
    "x=0\n",
    "y=0\n",
    "w=64\n",
    "h=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      " Y YY\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_size = 224  \n",
    "minValue = 70\n",
    "source = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "string = \" \"\n",
    "prev = \" \"\n",
    "update_interval = 200  \n",
    "\n",
    "while True:\n",
    "    ret, img = source.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    " \n",
    "    cv2.rectangle(img, (24, 24), (250, 250), (0, 255, 0), 2)\n",
    "    crop_img = gray[24:250, 24:250]\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "    cv2.putText(img, str(count // update_interval), (300, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)\n",
    "    \n",
    "    blur = cv2.GaussianBlur(crop_img, (5, 5), 2)\n",
    "    th3 = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    _, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    resized = cv2.resize(res, (img_size, img_size))\n",
    "    reshaped = np.stack((resized,) * 3, axis=-1) / 255.0  \n",
    "    reshaped = np.expand_dims(reshaped, axis=0)  \n",
    "    \n",
    "    if count % update_interval == 0:\n",
    "        result = model.predict(reshaped)\n",
    "        label = np.argmax(result, axis=1)[0]\n",
    "        prev = labels_dict[label]\n",
    "        if label == 0:\n",
    "            string += \" \"\n",
    "        else:\n",
    "            string += prev\n",
    "\n",
    "    cv2.putText(img, prev, (24, 14), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(img, string, (275, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200, 200, 200), 2)\n",
    "    \n",
    " \n",
    "    cv2.imshow(\"Gray\", res)\n",
    "    cv2.imshow('LIVE', img)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  \n",
    "        break\n",
    "\n",
    "print(string)\n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtts import gTTS \n",
    "  \n",
    " \n",
    "import os \n",
    "    \n",
    "\n",
    "language = 'en'\n",
    "\n",
    "myobj = gTTS(text=string, lang=language, slow=False) \n",
    "  \n",
    "\n",
    " \n",
    "myobj.save(r\"C:\\Users\\Darsh\\Desktop\\Project\\mp\\FinalCode\\speech.mp3\")\n",
    "\n",
    "  \n",
    " \n",
    "os.system(r\"C:\\Users\\Darsh\\Desktop\\Project\\mp\\FinalCode\\speech.mp3\") \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from playsound import playsound\n",
    "# playsound(r'C:\\Users\\Darsh\\Desktop\\Project\\mp\\Code\\welcome2121.mp3')\n",
    "import pygame\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load('C:\\\\Users\\\\Darsh\\\\Desktop\\\\Project\\\\mp\\\\Code\\\\welcome2121.mp3')\n",
    "pygame.mixer.music.play()\n",
    "while pygame.mixer.music.get_busy():  # Wait for the music to finish playing\n",
    "    continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
